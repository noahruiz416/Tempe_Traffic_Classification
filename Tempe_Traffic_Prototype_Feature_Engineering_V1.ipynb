{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tempe_Traffic_Prototype_Feature_Engineering_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZmr3pkpgqF1QLt/yg/jPq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahruiz416/Tempe_Traffic_Classification/blob/main/Tempe_Traffic_Prototype_Feature_Engineering_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This notebook will contain the initial feature engineering approaches that will be used. Decisions to transform or change certain varaibles will be explained"
      ],
      "metadata": {
        "id": "MNdh2WexOdio"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "id": "5IotTcbuOSf8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"traffic_data.2.csv\")"
      ],
      "metadata": {
        "id": "BJHtOumgOcbJ"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on Exploratory Analysis, I plan on combining certain features that are very similar. Additionally I may exclude certain variables as well. More in depth reasoning will be included in final report."
      ],
      "metadata": {
        "id": "5-YNgcEERsz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "Wi97HV4HS0Fb"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#custom functions to transform data\n",
        "\n",
        "#finds the median age between  drivers\n",
        "def median_age(data):\n",
        "  data['median_age'] = (data['Age_Drv1'] + data['Age_Drv2']) / 2\n",
        "  return data\n",
        "\n",
        "#helper function that contains the logic for whether or not drugs were involved in an accident\n",
        "def label_drugs(row):\n",
        "  if row['DrugUse_Drv1'] == \"Drugs\" or row['DrugUse_Drv2'] == \"Drugs\":\n",
        "    return 1 #drugs are involved\n",
        "  if row['DrugUse_Drv1'] != \"Drugs\" or row['DrugUse_Drv2'] != \"Drugs\":\n",
        "    return 0 #drugs are not involved\n",
        "\n",
        "#applying helper function in order to sort by rows\n",
        "def apply_drug_label(data):\n",
        "  data['drugs_involved'] = data.apply (lambda row: label_drugs(row), axis=1)\n",
        "  return data\n",
        "\n",
        "#helper function that contains the logic for whether or not alch was involved in an accident\n",
        "def label_alchol(row):\n",
        "  if row['AlcoholUse_Drv1'] == \"Drugs\" or row['AlcoholUse_Drv2'] == \"Drugs\":\n",
        "    return 1 #drugs are involved\n",
        "  if row['AlcoholUse_Drv1'] != \"Drugs\" or row['AlcoholUse_Drv2'] != \"Drugs\":\n",
        "    return 0 #drugs are not involved\n",
        "\n",
        "#applying helper function in order to sort by rows\n",
        "def apply_alchol_label(data):\n",
        "  data['alcohol_involved'] = data.apply (lambda row: label_alchol(row), axis=1)\n",
        "  return data\n",
        "\n",
        "#function to binary encode accidents as fatal or nonfatal\n",
        "def encode_fatal_accidents(data):\n",
        "  Severity = []\n",
        "  for row in data['Injuryseverity']:\n",
        "    if row != \"Fatal\":\n",
        "      Severity.append(0) #nonfatal\n",
        "    if row == \"Fatal\":\n",
        "      Severity.append(1) #fatal\n",
        "  data['Fatal_Non_Fatal'] = Severity\n",
        "  return data\n",
        "\n",
        "#drops unusable columns in Collisionmanner\n",
        "def fix_collision_manner(data):\n",
        "  data = data[data['Collisionmanner'].str.contains(\"10\")==False]\n",
        "  return data\n",
        "\n",
        "#drops unusable columns in Lightcondition\n",
        "def fix_light_condition(data):\n",
        "  data = data[data['Lightcondition'].str.contains(\"51\")==False]\n",
        "  data = data[data['Lightcondition'].str.contains(\"Unknown 51\")==False]\n",
        "  return data\n",
        "\n",
        "#drops outliers in age category\n",
        "def filter_age_outliers(data):\n",
        "  data.drop(data.index[data['Age_Drv1'] >= 100], inplace=True)\n",
        "  data.drop(data.index[data['Age_Drv2'] >= 100], inplace=True)\n",
        "  return data\n",
        "\n",
        "#drops unusable columns in Violations\n",
        "def fix_violations(data):\n",
        "  data = data[data['Violation1_Drv1'].str.contains(\"108\")==False]\n",
        "  data = data[data['Violation1_Drv1'].str.contains(\"109\")==False]\n",
        "  data = data[data['Violation1_Drv1'].str.contains(\"49\")==False]\n",
        "  return data\n",
        "\n",
        "#one hot encoding categorical features\n",
        "def nominal_encoding(data):\n",
        "  data = [['StreetName','Collisionmanner', 'Lightcondition', 'Weather', 'SurfaceCondition']] \n",
        "  data_dummies = pd.get_dummies(data)\n",
        "  return data_dummies\n",
        "\n",
        "#final piece to tie pipeline together\n",
        "def initial_input_vector(data):\n",
        "  pass"
      ],
      "metadata": {
        "id": "wazHP0qxUT1i"
      },
      "execution_count": 341,
      "outputs": []
    }
  ]
}